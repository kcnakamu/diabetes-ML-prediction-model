# Creates a machine learning model using a Diabetes prediction dataset

# Import necessary python libraries 
import pandas as pd 
import numpy as np
from matplotlib import pyplot as plt

# Read CSV file
df = pd.read_csv("/Users/aquachat77/Downloads/diabetes_prediction_dataset.csv")
#print(patients.head())
# sizes = df[""].value_counts(sort=1)
# print(sizes)

# Drop unnecessary columns
df.drop(["smoking_history"], axis = 1, inplace= True)
df.dropna(inplace = True)

# Apply one-hot encoding to all categorical variables, including 'gender'
df_encoded = pd.get_dummies(df, drop_first=True)

# Define dependent and independent variables 
Y = df_encoded['diabetes'].values
X = df_encoded.drop(labels=['diabetes'], axis=1)

# Split data into training and testing datasets using 80/20 split
from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state=20)

# # We are predicting a binary result (diabetes vs not), so we will use classifier instead of regressor
from sklearn.ensemble import RandomForestClassifier
model = RandomForestClassifier(n_estimators=10,random_state=30)
model.fit(X_train,Y_train)

prediction_test = model.predict(X_test)
#print(prediction_test)

from sklearn import metrics
print("Model Accuracy = ", metrics.accuracy_score(Y_test,prediction_test))

# Feature Importance 
feature_list = list(X.columns)
print("Input feature list: " + str(feature_list))
feature_imp = pd.Series(model.feature_importances_,index = feature_list).sort_values(ascending = False)
print("Ordered list of key contriuting features: \n" + str(feature_imp))

# Save my trained model
import joblib
trained_model = model
joblib.dump(trained_model, "diabetes_model.joblib")
